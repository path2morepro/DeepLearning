{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Image Classification Laboration\n",
    "\n",
    "\n",
    "Images used in this laboration are from [CIFAR10](https://en.wikipedia.org/wiki/CIFAR-10). The CIFAR10 dataset contains 60,000 32x32 color images in 10 different classes. The 10 different classes represent airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. There are 6,000 images of each class. \n",
    "\n",
    "Your task is to make a classifier, using a convolutional neural network, that can correctly classify each image into the correct class.\n",
    "\n",
    "Complete the code flagged throughout the elaboration and **answer all the questions in the notebook**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setups\n",
    "# Automatically reload modules when changed\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Convolutions\n",
    "\n",
    "In the next sections you will familiarize yourself with 2D convolutions.\n",
    "\n",
    "## 1.1 What is a convolution?\n",
    "\n",
    "To understand a bit more about convolutions, we will first test the convolution function in `scipy` using a number of classical filters. \n",
    "\n",
    "Convolve the image with Gaussian filter, a Sobel X filter, and a Sobel Y filter, using the function `convolve2d` in `signal` from scipy (see the [documentation](https://docs.scipy.org/doc/scipy-1.15.0/reference/generated/scipy.signal.convolve2d.html\n",
    ") for more details).\n",
    "\n",
    "\n",
    "In a CNN, many filters are applied in each layer, and the filter coefficients are learned through back propagation (which is in contrast to traditional image processing, where the filters are designed by an expert).\n",
    "\n",
    "Run the cell below to define a Gaussian filter and a Sobel X and Y filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "import numpy as np\n",
    "\n",
    "# Get a test image\n",
    "from scipy import datasets\n",
    "image = datasets.ascent()\n",
    "\n",
    "# Define a help function for creating a Gaussian filter\n",
    "def matlab_style_gauss2D(shape=(3,3),sigma=0.5):\n",
    "    \"\"\"\n",
    "    2D gaussian mask - should give the same result as MATLAB's\n",
    "    fspecial('gaussian',[shape],[sigma])\n",
    "    \"\"\"\n",
    "    m,n = [(ss-1.)/2. for ss in shape]\n",
    "    y,x = np.ogrid[-m:m+1,-n:n+1]\n",
    "    h = np.exp( -(x*x + y*y) / (2.*sigma*sigma) )\n",
    "    h[ h < np.finfo(h.dtype).eps*h.max() ] = 0\n",
    "    sumh = h.sum()\n",
    "    if sumh != 0:\n",
    "        h /= sumh\n",
    "    return h\n",
    "\n",
    "# Create Gaussian filter with certain size and standard deviation\n",
    "gaussFilter = matlab_style_gauss2D((15,15),4)\n",
    "\n",
    "# Define filter kernels for SobelX and Sobely\n",
    "sobelX = np.array([[ 1, 0,  -1],\n",
    "                    [2, 0, -2],\n",
    "                    [1, 0, -1]]) \n",
    "\n",
    "sobelY = np.array([[ 1, 2,  1],\n",
    "                    [0, 0, 0],\n",
    "                    [-1, -2, -1]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# === Your code here =========================\n",
    "# -------------------------------------------- \n",
    "# Perform convolution using the function 'convolve2d' for the different filters\n",
    "\n",
    "filterResponseGauss = ???\n",
    "filterResponseSobelX = ???\n",
    "filterResponseSobelY = ???\n",
    "\n",
    "# ============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Show filter responses\n",
    "fig, (ax_orig, ax_filt1, ax_filt2, ax_filt3) = plt.subplots(1, 4, figsize=(20, 6))\n",
    "ax_orig.imshow(image, cmap='gray')\n",
    "ax_orig.set_title('Original')\n",
    "ax_orig.set_axis_off()\n",
    "ax_filt1.imshow(np.absolute(filterResponseGauss), cmap='gray')\n",
    "ax_filt1.set_title('Gaussian filter response')\n",
    "ax_filt1.set_axis_off()\n",
    "ax_filt2.imshow(np.absolute(filterResponseSobelX), cmap='gray')\n",
    "ax_filt2.set_title('SobelX filter response')\n",
    "ax_filt2.set_axis_off()\n",
    "ax_filt3.imshow(np.absolute(filterResponseSobelY), cmap='gray')\n",
    "ax_filt3.set_title('SobelY filter response')\n",
    "ax_filt3.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Understanding convolutions\n",
    "\n",
    "#### **<span style=\"color:red\">Questions</span>**\n",
    "\n",
    "1. What do the 3 different filters (Gaussian, SobelX, SobelY) do to the original image?\n",
    "\n",
    "2. What is the size of the original image? How many channels does it have? How many channels does a color image normally have?\n",
    "\n",
    "3. What is the size of the different filters?\n",
    "\n",
    "4. What is the size of the filter response if mode 'same' is used for the convolution ?\n",
    "\n",
    "5. What is the size of the filter response if mode 'valid' is used for the convolution? How does the size of the valid filter response depend on the size of the filter? \n",
    "\n",
    "6. Why are 'valid' convolutions a problem for CNNs with many layers?\n",
    "\n",
    "#### **<span style=\"color:green\">Answers</span>**\n",
    "[Your answer here]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# === Your code here =========================\n",
    "# -------------------------------------------- \n",
    "# Your code for checking sizes of image and filter responses\n",
    "???\n",
    "\n",
    "# ============================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Part 2: Get a graphics card\n",
    "\n",
    "Skip the next cell if you run on the CPU.\n",
    "\n",
    "If your computer has a dedicated graphics card and you would like to use it, we need to make sure that our script can see the graphics card that will be used. The graphics cards will perform all the time consuming calculations in every training iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "# Ignore FutureWarning from numpy\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    " \n",
    "# The GPU id to use, usually either \"0\" or \"1\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "# This sets the GPU to allocate memory only as needed\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) != 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True) \n",
    "    print(\"Running on GPU\")\n",
    "else:\n",
    "    print('No GPU available.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How fast is the graphics card?\n",
    "\n",
    "\n",
    "#### **<span style=\"color:red\">Questions</span>**\n",
    "\n",
    "7. Why are the filters used for a color image of size 7 x 7 x 3, and not 7 x 7 ? \n",
    "\n",
    "8. What operation is performed by the 'Conv2D' layer? Is it a standard 2D convolution, as performed by the function signal.convolve2d we just tested?\n",
    "\n",
    "9.  Pretend that everyone is using an Nvidia RTX 3090 graphics card, how many CUDA cores does it have? How much memory does the graphics card have?\n",
    "\n",
    "10. How much memory does the graphics card have?\n",
    "\n",
    "11. What is stored in the GPU memory while training a CNN?\n",
    "\n",
    "12. Do you think that a graphics card, compared to the CPU, is equally faster for convolving a batch of 1,000 images, compared to convolving a batch of 3 images? Motivate your answer.\n",
    "\n",
    "\n",
    "#### **<span style=\"color:green\">Answers</span>**\n",
    "[Your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Dataset\n",
    "\n",
    "In the following section you will load the CIFAR10 dataset, check few samples, perform some preprocessing on the images and the labels, and split the data into training, validation and testing.\n",
    "\n",
    "## 3.1 Load the dataset\n",
    "\n",
    "Run the following section to load the CIFAR10 data, take a total of 10.000 training/validation samples and 2000 testing samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# Download CIFAR train and test data\n",
    "(X, Y), (Xtest, Ytest) = cifar10.load_data()\n",
    "\n",
    "print(\"Training/validation images have size {} and labels have size {} \".format(X.shape, Y.shape))\n",
    "print(\"Test images have size {} and labels have size {} \\n \".format(Xtest.shape, Ytest.shape))\n",
    "\n",
    "# Reduce the number of images for training/validation and testing to 10000 and 2000 respectively, \n",
    "# to reduce processing time for this elaboration. \n",
    "X = X[0:10000]\n",
    "Y = Y[0:10000]\n",
    "\n",
    "Xtest = Xtest[0:2000]\n",
    "Ytest = Ytest[0:2000]\n",
    "\n",
    "Ytestint = Ytest\n",
    "\n",
    "print(\"Reduced training/validation images have size %s and labels have size %s \" % (X.shape, Y.shape))\n",
    "print(\"Reduced test images have size %s and labels have size %s \\n\" % (Xtest.shape, Ytest.shape))\n",
    "\n",
    "# Check that we have some training examples from each class\n",
    "for i in range(10):\n",
    "    print(\"Number of training/validation examples for class {} is {}\" .format(i,np.sum(Y == i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at some of the training examples, this cell is already finished. You will see different examples every time you run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "for i in range(18):\n",
    "    idx = np.random.randint(7500)\n",
    "    label = Y[idx,0]\n",
    "    \n",
    "    plt.subplot(3,6,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(X[idx])\n",
    "    plt.title(\"Class: {} ({})\".format(label, classes[label]))\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3.2 Split data into training, validation and testing\n",
    "Split your data (X, Y) into training (Xtrain, Ytrain) and validation (Xval, Yval), so that we have training, validation and test datasets (as in the previous laboration).\n",
    "\n",
    "We use the `train_test_split` function from scikit learn (see the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) for more details) to obtain 25% validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --------------------------------------------\n",
    "# === Your code here =========================\n",
    "# --------------------------------------------\n",
    "\n",
    "# split the original dataset into 70% Training and 30% Temp\n",
    "Xtrain, Xval, Ytrain, Yval = ???\n",
    "\n",
    "\n",
    "\n",
    "# Print the size of training data, validation data and test data\n",
    "???\n",
    "\n",
    "# ============================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Image Preprocessing\n",
    "\n",
    "Lets perform some preprocessing. The images are stored as uint8, i.e. 8 bit unsigned integers, but need to be converted to 32 bit floats. We also make sure that the range is -1 to 1, instead of 0 - 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datatype for Xtrain, Xval, Xtest, to float32\n",
    "Xtrain = Xtrain.astype('float32')\n",
    "Xval = Xval.astype('float32')\n",
    "Xtest = Xtest.astype('float32')\n",
    "\n",
    "# Change range of pixel values to [-1,1]\n",
    "Xtrain = Xtrain / 127.5 - 1\n",
    "Xval = Xval / 127.5 - 1\n",
    "Xtest = Xtest / 127.5 - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3.4 Label preprocessing\n",
    "\n",
    "The labels (Y) need to be converted from e.g. '4' to \"hot encoded\", i.e. to a vector of type [0, 0, 0, 1, 0, 0, 0, 0, 0, 0] . We use the `to_categorical`function in Keras (see the [documentation](https://keras.io/api/utils/python_utils/#to_categorical-function) for details on how to use it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Print shapes before converting the labels\n",
    "print('Ytrain has size {}.'.format(Ytrain.shape))\n",
    "print('Yval has size {}.'.format(Yval.shape))\n",
    "print('Ytest has size {}.'.format(Ytest.shape))\n",
    "\n",
    "\n",
    "# --------------------------------------------\n",
    "# === Your code here =========================\n",
    "# --------------------------------------------\n",
    "\n",
    "# Your code for converting Ytrain, Yval, Ytest to categorical\n",
    "Ytrain = to_categorical(???)\n",
    "Yval = ???\n",
    "Ytest = ???\n",
    "\n",
    "# Print shapes after converting the labels\n",
    "???\n",
    "\n",
    "# ============================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: 2D CNN\n",
    "\n",
    "In the following sections you will build a 2D CNN model and will train it to perform classification on the CIFAR10 dataset. \n",
    "\n",
    "## 4.1 Build CNN model\n",
    "\n",
    "Start by implementing the `build_CNN` function in the `utilities.py` file. Below you can find the specifications on how your `build_CNN` function should build the model:\n",
    "- Each convolutional layer is composed by: `2D convolution` -> `batch normalization` -> `max pooling`.\n",
    "- The `2D convolution` uses a 3 x 3 kernel size, padding='same' and a number of starting filter that is an input to the `build_CNN` function. The number of filters doubles with each convolutional layer (e.g. 32, 64, 128, etc.)\n",
    "- The max pooling layers should have a pool size of 2 x 2.\n",
    "- After the convolutional layers comes a flatten layer, followed by a number of intermediate dense layers. \n",
    "- The number of nodes in the intermediate dense layers before the final dense layer is an input to the `build_CNN` function. The intermediate dense layers use `relu` activation functions and each is followed by `batch normalization`.\n",
    "- The final dense layer should have 10 nodes (=the number of classes in this elaboration) and `softmax` activation. \n",
    "\n",
    "Here are some relevant functions that you should use in `build_CNN`. For a complete list of functions and their definitions see the [keras documentation](https://keras.io/api/):\n",
    "\n",
    "- `model.add()`, adds a layer to the network;\n",
    "- `Dense()`, a dense network layer. See the [documentation](https://keras.io/api/layers/core_layers/dense/) what are the input options and outputs of the `Dense()` function. \n",
    "- `Conv2D()` performs 2D convolutions with a number of filters with a certain size (e.g. 3 x 3) (see [documentation](https://keras.io/api/layers/convolution_layers/convolution2d/)). \n",
    "- `BatchNormalization()`, perform batch normalization (see [documentation](https://keras.io/api/layers/normalization_layers/batch_normalization/)).\n",
    "- `MaxPooling2D()`, saves the max for a given pool size, results in down sampling (see [documentation](https://keras.io/api/layers/pooling_layers/max_pooling2d/)).\n",
    "- `Flatten()`, flatten a multi-channel tensor into a long vector (see [documentation](https://keras.io/api/layers/reshaping_layers/flatten/)).\n",
    "- `model.compile()`, compiles the model. You can set the input metrics=['accuracy'] to print the classification accuracy during the training.\n",
    "- cost and loss functions: check the [documentation](https://keras.io/losses/) and chose a loss function for binary classification.\n",
    "\n",
    "To get more information in model [compile](https://keras.io/api/models/model_training_apis/#compile-method), [training](https://keras.io/api/models/model_training_apis/#fit-method) and [evaluation](https://keras.io/api/models/model_training_apis/#evaluate-method) see the relevant documentation.\n",
    "\n",
    "Here you can start with the `Adam` optimizer when compiling the model.\n",
    "\n",
    "Use the following cell to test your `build_CNN` utility function. Remember to import a relevant cost function for multi-class classification from [keras.losses](https://keras.io/losses/) which relates to how many classes you have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import utilities\n",
    "from utilities import build_CNN\n",
    "\n",
    "# --------------------------------------------\n",
    "# === Your code here =========================\n",
    "# --------------------------------------------\n",
    "\n",
    "# import a suitable loss function from keras.losses and use as input to the build_DNN function.\n",
    "from tf_keras.losses import ???\n",
    "\n",
    "# Build a DNN model following the specifications above\n",
    "model = build_CNN(???)\n",
    "\n",
    "# ============================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Train 2D CNN\n",
    "\n",
    "Time to train the CNN!\n",
    "\n",
    "Start with a model with 2 convolutional layers where the first layer has have 16 filters, and with no intermediate dense layers.\n",
    "\n",
    "Set the training parameters, build the model and run the training. \n",
    "\n",
    "Use the following training parameters:\n",
    "- `batch_size=20`\n",
    "- `epochs=20`\n",
    "- `learning_rate=0.01`\n",
    "\n",
    "Relevant functions:\n",
    "- `build_CNN`, the function that you defined in the `utilities.py` file.\n",
    "- `model.fit()`, train the model with some training data (see [documentation](https://keras.io/api/models/model_training_apis/#fit-method)).\n",
    "- `model.evaluate()`, apply the trained model to some test data (see [documentation](https://keras.io/api/models/model_training_apis/#evaluate-method))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 convolutional layers, no intermediate dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# === Your code here =========================\n",
    "# --------------------------------------------\n",
    "\n",
    "# Setup some training parameters\n",
    "batch_size = ???\n",
    "epochs = ???\n",
    "input_shape = ???\n",
    "learning_rate = ???\n",
    "\n",
    "# Build model\n",
    "model1 = ???\n",
    "\n",
    "# Train the model  using training data and validation data\n",
    "history1 = ???\n",
    "\n",
    "# ============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# === Your code here =========================\n",
    "# --------------------------------------------\n",
    "\n",
    "# Evaluate the trained model on test set, not used in training or validation\n",
    "score = ???\n",
    "\n",
    "# ============================================\n",
    "\n",
    "print('Test loss: %.4f' % score[0])\n",
    "print('Test accuracy: %.4f' % score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import plot_results\n",
    "# Plot the history from the training run\n",
    "plot_results(history1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  4.3 Improving model performance\n",
    "\n",
    "Write down the test accuracy, are you satisfied with the classifier performance (random chance is 10%)? \n",
    "\n",
    "#### **<span style=\"color:red\">Questions</span>**\n",
    "13. How big is the difference between training and test accuracy?\n",
    "\n",
    "14. For the DNN elaboration we used a batch size of 10.000, why do we need to use a smaller batch size in this elaboration?\n",
    "\n",
    "#### **<span style=\"color:green\">Answers</span>**\n",
    "[Your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with several model configurations in the following sections. \n",
    "\n",
    "### 2 convolutional layers with 16 starting filters and 1 intermediate dense layer (50 nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# === Your code here =========================\n",
    "# --------------------------------------------\n",
    "\n",
    "# Build and train model\n",
    "model1 = ???\n",
    "\n",
    "history1 = ???\n",
    "\n",
    "# Evaluate model on test data\n",
    "score = ???\n",
    "\n",
    "# ============================================\n",
    "\n",
    "print('Test loss: %.4f' % score[0])\n",
    "print('Test accuracy: %.4f' % score[1])\n",
    "\n",
    "# Plot the history from the training run\n",
    "plot_results(history1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 convolutional layers with 16 starting filters and 1 intermediate dense layer (50 nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# === Your code here =========================\n",
    "# --------------------------------------------\n",
    "\n",
    "# Build and train model\n",
    "model2 = ???\n",
    "\n",
    "history2 = ???\n",
    "\n",
    "# Evaluate model on test data\n",
    "score = ???\n",
    "\n",
    "# ============================================\n",
    "\n",
    "print('Test loss: %.4f' % score[0])\n",
    "print('Test accuracy: %.4f' % score[1])\n",
    "\n",
    "# Plot the history from the training run\n",
    "plot_results(history2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Plot the CNN architecture and understand the internal model dimensions\n",
    "\n",
    "To understand your network better, print the architecture using `model.summary()`\n",
    "\n",
    "#### **<span style=\"color:red\">Questions</span>**\n",
    "\n",
    "15. How many trainable parameters does your network have? Which part of the network contains most of the parameters?\n",
    "    \n",
    "16. What is the input to and output of a Conv2D layer? What are the dimensions of the input and output? \n",
    "17. Is the batch size always the first dimension of each 4D tensor? Check the [documentation](https://keras.io/layers/convolutional/) for Conv2D.\n",
    "18. If a convolutional layer that contains 128 filters is applied to an input with 32 channels, what is the number of channels in the output?\n",
    "19. Why is the number of parameters in each Conv2D layer *not* equal to the number of filters times the number of filter coefficients per filter (plus biases)?\n",
    "20. How does MaxPooling help in reducing the number of parameters to train?\n",
    "\n",
    "#### **<span style=\"color:green\">Answers</span>**\n",
    "[Your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  4.5 Dropout regularization\n",
    "\n",
    "Add dropout regularization between each intermediate dense layer, with dropout probability 50%.\n",
    "\n",
    "#### **<span style=\"color:red\">Questions</span>**\n",
    "\n",
    "21. How much did the test accuracy improve with dropout, compared to without dropout?\n",
    "\n",
    "22. What other types of regularization can be applied? How can you add `L2 regularization` for the convolutional layers?\n",
    " \n",
    "#### **<span style=\"color:green\">Answers</span>**\n",
    "[Your answer here]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 convolutional layers with 16 starting filters and 1 intermediate dense layer (50 nodes) with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# === Your code here =========================\n",
    "# --------------------------------------------\n",
    "\n",
    "# Setup some training parameters\n",
    "batch_size = ???\n",
    "epochs = ???\n",
    "input_shape = ???\n",
    "learning_rate = ???\n",
    "\n",
    "# Build and train model\n",
    "model3 = ???\n",
    "\n",
    "# Train the model using training data and validation data\n",
    "history3 = ???\n",
    "\n",
    "# Evaluate model on test data\n",
    "score = ???\n",
    "\n",
    "# ============================================\n",
    "\n",
    "print('Test loss: %.4f' % score[0])\n",
    "print('Test accuracy: %.4f' % score[1])\n",
    "\n",
    "plot_results(history3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  4.6 Tweaking model performance\n",
    "\n",
    "You have now seen the basic building blocks of a 2D CNN. To further improve performance involves changing the number of convolutional layers, the number of filters per layer, the number of intermediate dense layers, the number of nodes in the intermediate dense layers, batch size, learning rate, number of epochs, etc. Spend some time (30 - 90 minutes) testing different settings.\n",
    "\n",
    "#### **<span style=\"color:red\">Questions</span>**\n",
    "\n",
    "23. How high test accuracy can you obtain? What is your best configuration?\n",
    "\n",
    "#### **<span style=\"color:green\">Answers</span>**\n",
    "[Your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Your best config*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# === Your code here =========================\n",
    "# --------------------------------------------\n",
    "\n",
    "# Setup some training parameters\n",
    "batch_size = ???\n",
    "epochs = ???\n",
    "input_shape = ???\n",
    "learning_rate = ???\n",
    "\n",
    "# Build and train model. Here experiment with several model architecture configurations to obtain the best performance.\n",
    "model4 = ???\n",
    "\n",
    "history4 = ???\n",
    "\n",
    "# Evaluate model on test data\n",
    "score = ???\n",
    "\n",
    "# ============================================\n",
    "\n",
    "print('Test loss: %.4f' % score[0])\n",
    "print('Test accuracy: %.4f' % score[1])\n",
    "\n",
    "# Plot the history from the training run\n",
    "plot_results(history4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Model generalization\n",
    "\n",
    "How high is the test accuracy if we rotate the test images? In other words, how good is the CNN at generalizing to rotated images?\n",
    "\n",
    "Rotate each test image 90 degrees, the cells are already finished.\n",
    "\n",
    "#### **<span style=\"color:red\">Questions</span>**\n",
    "\n",
    "24. What is the test accuracy for rotated test images, compared to test images without rotation? Explain the difference in accuracy.\n",
    "\n",
    "#### **<span style=\"color:green\">Answers</span>**\n",
    "[Your answer here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import myrotate\n",
    "# Visualize some rotated images\n",
    "# Rotate the test images 90 degrees\n",
    "Xtest_rotated = myrotate(Xtest)\n",
    "\n",
    "# Look at some rotated images\n",
    "plt.figure(figsize=(16,4))\n",
    "for i in range(10):\n",
    "    idx = np.random.randint(500)\n",
    "    \n",
    "    plt.subplot(2,10,i+1)\n",
    "    plt.imshow(Xtest[idx]/2+0.5)\n",
    "    plt.title(\"Original\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(2,10,i+11)\n",
    "    plt.imshow(Xtest_rotated[idx]/2+0.5)\n",
    "    plt.title(\"Rotated\")\n",
    "    plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the trained model on rotated test set\n",
    "score = model4.evaluate(Xtest_rotated, Ytest, verbose=0)\n",
    "print('Test loss: %.4f' % score[0])\n",
    "print('Test accuracy: %.4f' % score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  5.1 Augmentation using Keras `ImageDataGenerator`\n",
    "\n",
    "We can increase the number of training images through data augmentation (we now ignore that CIFAR10 actually has 60 000 training images). Image augmentation is about creating similar images, by performing operations such as rotation, scaling, elastic deformations and flipping of existing images. This will prevent overfitting, especially if all the training images are in a certain orientation.\n",
    "\n",
    "We will perform the augmentation on the fly, using a built-in function in Keras, called `ImageDataGenerator`. In particular, we will use the `flow()` functionality (see the [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator) for more details).\n",
    "\n",
    "Make sure to use different subsets for training and validation when you calling `flow()` on the training data generator in `model.fit()`, otherwise you will validate on the same data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all 60 000 training images again. ImageDataGenerator manages validation data on its own\n",
    "\n",
    "# re-load the CIFAR10 train and test data\n",
    "(X, Y), (Xtest, Ytest) = cifar10.load_data()\n",
    "\n",
    "# Reduce the number of images for training/validation and testing to 10000 and 2000 respectively, \n",
    "# to reduce processing time for this elaboration. \n",
    "X = X[0:10000]\n",
    "Y = Y[0:10000]\n",
    "\n",
    "Xtest = Xtest[0:2000]\n",
    "Ytest = Ytest[0:2000]\n",
    "\n",
    "# Change data type and rescale range\n",
    "X = X.astype('float32')\n",
    "Xtest = Xtest.astype('float32')\n",
    "\n",
    "X = X / 127.5 - 1\n",
    "Xtest = Xtest / 127.5 - 1\n",
    "\n",
    "\n",
    "# Convert labels to hot encoding\n",
    "Y = to_categorical(Y, 10)\n",
    "Ytest = to_categorical(Ytest, 10)\n",
    "\n",
    "print(\"Training/validation images have size {} and labels have size {} \".format(X.shape, Y.shape))\n",
    "print(\"Test images have size {} and labels have size {} \\n \".format(Xtest.shape, Ytest.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# --------------------------------------------\n",
    "# === Your code here =========================\n",
    "# --------------------------------------------\n",
    "\n",
    "# Use a rotation range of 30 degrees, horizontal and vertical flipping\n",
    "# Set up image data generator\n",
    "image_dataset = ImageDataGenerator(???)\n",
    "\n",
    "\n",
    "# ============================================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **<span style=\"color:red\">Questions</span>**\n",
    "\n",
    "25. How would you change the code for the image generator if you cannot fit all training images in CPU memory? What is the disadvantage of doing that change?\n",
    "\n",
    "#### **<span style=\"color:green\">Answers</span>**\n",
    "[Your answer here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some augmented images\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "for i in range(18):\n",
    "    (im, label) = train_flow.next()\n",
    "    im = (im[0] + 1) * 127.5\n",
    "    im = im.astype('int')\n",
    "    label = np.flatnonzero(label)[0]\n",
    "    \n",
    "    plt.subplot(3,6,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(im)\n",
    "    plt.title(\"Class: {} ({})\".format(label, classes[label]))\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Train the CNN with images from the generator\n",
    "\n",
    "Check the documentation for the [`model.fit`](https://keras.io/api/models/model_training_apis/#fit-method) method how to use it with a generator instead of a fix dataset (numpy arrays).\n",
    "\n",
    "To make the comparison fair to training without augmentation\n",
    "\n",
    "- `steps_per_epoch` should be set to: `len(Xtrain)/batch_size`\n",
    "- `validation_steps` should be set to: `len(Xval)/batch_size`\n",
    "    \n",
    "This is required since with a generator, the fit function will not know how many examples your original dataset has.\n",
    "\n",
    "#### **<span style=\"color:red\">Questions</span>**\n",
    "\n",
    "26. How quickly is the training accuracy increasing compared to without augmentation? Explain why there is a difference compared to without augmentation. We are here talking about the number of training epochs required to reach a certain accuracy, and not the training time in seconds. What parameter is necessary to change to perform more training?\n",
    "\n",
    "27. What other types of image augmentation can be applied, compared to what we use here?\n",
    "\n",
    "#### **<span style=\"color:green\">Answers</span>**\n",
    "[Your answer here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# === Your code here =========================\n",
    "# --------------------------------------------\n",
    "\n",
    "# Setup training parameters\n",
    "batch_size = ???\n",
    "epochs = ???\n",
    "input_shape = ???\n",
    "\n",
    "# Build model (your best config)\n",
    "model6 = build_CNN(???)\n",
    "\n",
    "# Set up training and validation dataset flows from image_dataset\n",
    "# flow() for training data\n",
    "train_flow = image_dataset.flow(???)\n",
    "\n",
    "# flow() for validation data\n",
    "val_flow = image_dataset.flow(???)\n",
    "\n",
    "\n",
    "# Train the model using on the fly augmentation\n",
    "history6 = model6.fit(???)\n",
    "\n",
    "# ============================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there is still a big difference in accuracy for original and rotated test images\n",
    "\n",
    "# Evaluate the trained model on original test set\n",
    "score = model6.evaluate(Xtest, Ytest, batch_size = batch_size, verbose=0)\n",
    "print('Test loss: %.4f' % score[0])\n",
    "print('Test accuracy: %.4f' % score[1])\n",
    "\n",
    "# Evaluate the trained model on rotated test set\n",
    "score = model6.evaluate(Xtest_rotated, Ytest, batch_size = batch_size, verbose=0)\n",
    "print('Test loss: %.4f' % score[0])\n",
    "print('Test accuracy: %.4f' % score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the history from the training run\n",
    "plot_results(history6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot misclassified images\n",
    "\n",
    "Lets plot some images where the CNN performed badly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find misclassified images\n",
    "y_pred=model6.predict(Xtest, verbose=0) \n",
    "y_pred=np.argmax(y_pred,axis=1)\n",
    "\n",
    "y_correct = np.argmax(Ytest,axis=-1)\n",
    "\n",
    "miss = np.flatnonzero(y_correct != y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a few of them\n",
    "plt.figure(figsize=(15,4))\n",
    "perm = np.random.permutation(miss)\n",
    "for i in range(18):\n",
    "    im = (Xtest[perm[i]] + 1) * 127.5\n",
    "    im = im.astype('int')\n",
    "    label_correct = y_correct[perm[i]]\n",
    "    label_pred = y_pred[perm[i]]\n",
    "    \n",
    "    plt.subplot(3,6,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(im)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"{}, classified as {}\".format(classes[label_correct], classes[label_pred]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  5.3 Testing on another size\n",
    "\n",
    "#### **<span style=\"color:red\">Questions</span>**\n",
    "\n",
    "28. This CNN has been trained on 32 x 32 images, can it be applied to images of another size? If not, why is this the case?\n",
    "\n",
    "29. Is it possible to design a CNN that can be trained on images of one size, and then applied to an image of any size? How?\n",
    "\n",
    "#### **<span style=\"color:green\">Answers</span>**\n",
    "[Your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 6: Carbon footprint\n",
    "\n",
    "In this next section we will evaluate the carbon footprint of training our CNN model. In particular we will look at the effect of training hyper parameters of carbon footprint. You can read more about this topic [here](https://arxiv.org/abs/2007.03051) or [here](https://research.google/blog/good-news-about-the-carbon-footprint-of-machine-learning-training/). \n",
    "\n",
    "In this lab we will use the `carbontracker` library that easily integrates with any model training routine. See the example in the [documentation](https://github.com/lfwa/carbontracker?tab=readme-ov-file) on how to use the carbon tracker.\n",
    "\n",
    "#### **<span style=\"color:red\">Questions</span>**\n",
    "\n",
    "28. Keeping the model architecture fixed, which training parameter impacts the carbon footprint? \n",
    "    \n",
    "29. The choice of batch size can dramatically impact carbon foot print: why is this the case?\n",
    "    \n",
    "30. Assume that you have a model with 100 million parameters running in the backend of a service with 5 million users. How can the carbon footprint of using this model be reduced?\n",
    "\n",
    "#### **<span style=\"color:green\">Answers</span>**\n",
    "[Your answer here]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from carbontracker.tracker import CarbonTracker\n",
    "\n",
    "# --------------------------------------------\n",
    "# === Your code here =========================\n",
    "# --------------------------------------------\n",
    "# Setup training parameters\n",
    "batch_size = ???\n",
    "epochs = ???\n",
    "input_shape = ???\n",
    "\n",
    "# Build model (your best config)\n",
    "model7 = ???\n",
    "\n",
    "# Create a CarbonTracker object\n",
    "tracker = CarbonTracker(epochs=???)\n",
    "\n",
    "# start carbon tracking\n",
    "tracker.epoch_start()\n",
    "\n",
    "# fit model\n",
    "model.fit(???)\n",
    "\n",
    "tracker.epoch_end()\n",
    "\n",
    "# ============================================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 7: Pre-trained 2D CNNs\n",
    "\n",
    "There are many deep 2D CNNs that have been pre-trained using the large ImageNet database (several million images, 1000 classes). Import a pre-trained ResNet50 network from Keras applications. Show the network using `model.summary()`\n",
    "\n",
    "#### **<span style=\"color:red\">Questions</span>**\n",
    "\n",
    "31. How many convolutional layers does ResNet50 have? \n",
    "\n",
    "32. How many trainable parameters does the ResNet50 network have? \n",
    "\n",
    "33. What is the size of the images that ResNet50 expects as input?\n",
    "\n",
    "34. Using the answer to question 30, explain why the second derivative is seldom used when training deep networks.\n",
    "\n",
    "35. What do you expect the carbon footprint of using pre-trained networks to be compared to training a model from scratch?\n",
    "\n",
    "#### **<span style=\"color:green\">Answers</span>**\n",
    "[Your answer here]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading the pre-trained CNN, apply it to 5 random color images that you download and copy to the cloud machine or your own computer. Are the predictions correct? How certain is the network of each image class?\n",
    "\n",
    "These pre-trained networks can be fine tuned to your specific data, and normally only the last layers need to be re-trained, but it will still be too time consuming to do in this elaboration.\n",
    "\n",
    "Some useful functions:\n",
    "- `load_img` and `img_to_array` in [tf_keras.utils](https://www.tensorflow.org/api_docs/python/tf/keras/utils).\n",
    "- `ResNet50` in [tf_keras.applications.ResNet50](tf.keras.applications.ResNet50).\n",
    "- `preprocess_input` in [tf_keras.applications.resnet](https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet/preprocess_input).\n",
    "- `decode_predictions` in [tf_keras.applications.resnet](https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet/decode_predictions).\n",
    "- `expand_dims` in [numpy](https://numpy.org/doc/stable/reference/generated/numpy.expand_dims.html).\n",
    "\n",
    "See [keras applications](https://keras.io/api/applications/) and the keras [resnet50-function](https://keras.io/api/applications/resnet/#resnet50-function) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------\n",
    "# === Your code here =========================\n",
    "# --------------------------------------------\n",
    "# import the necessary libraries and functions \n",
    "from tf_keras.applications import ???\n",
    "from tf_keras.utils import ???, ???\n",
    "from tf_keras.applications.resnet import ???, ???\n",
    "\n",
    "# load the pre-trained ResNet50 model\n",
    "resnet50 = ???\n",
    "\n",
    "# print the model summary\n",
    "???\n",
    "\n",
    "# load the image and preprocess it\n",
    "image = ???\n",
    "\n",
    "# predict the image\n",
    "label = ???\n",
    "\n",
    "# print the predicted label\n",
    "print(label)\n",
    "\n",
    "# ============================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 8 (OPTIONAL)\n",
    "\n",
    "Set up `Ray Tune` and run automatic hyper parameter optimization for the CNN model as we have done in the DNN lab. Remember that you have to define the `train_CNN` function, specify the hyper parameter search space and the number of samples to evaluate, among other."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "732a83_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
